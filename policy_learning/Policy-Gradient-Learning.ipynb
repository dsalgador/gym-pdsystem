{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsalgador/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "The algorithm is tested on the PDSystemEnv  gym task \n",
    "and developed with Tensorflow\n",
    "\n",
    "Author: Daniel Salgado Rojo\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "import gym_pdsystem\n",
    "from gym import wrappers\n",
    "#import tflearn\n",
    "import argparse\n",
    "import pprint as pp\n",
    "\n",
    "#from ddpg.replay_buffer import ReplayBuffer\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "from gym_pdsystem.envs.pdsystem_env import PDSystemEnv\n",
    "\n",
    "import gym_pdsystem.utils.utilsq as ut\n",
    "import gym_pdsystem.utils.constants as ct\n",
    "\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "#TO OMMIT WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Example n=5, k = 2\n",
    "\n",
    "TANK_MAX_LOADS = np.array([100., 200, 100., 800., 200.])\n",
    "LEVEL_PERCENTAGES = np.array([ #b , c, e\n",
    "                                                [0.02, 0.31, 0.9],\n",
    "                                                [0.01, 0.03, 0.9],\n",
    "                                                [0.05, 0.16, 0.9],\n",
    "                                                [0.07, 0.14, 0.85],\n",
    "                                                [0.08, 0.26, 0.9]\n",
    "                                                   ])\n",
    "\n",
    "TRUCK_MAX_LOADS = np.array([70.,130.])\n",
    "\n",
    "GRAPH_WEIGHTS = np.array([32., 159., 162., 156.,156., 0.])\n",
    "DISCRETE = True\n",
    "############################################################\n",
    "\n",
    "env = gym.make(\"PDSystemEnv-v0\")\n",
    "episode_length = 30\n",
    "env._max_episode_steps = episode_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_action(int_action: int, env):\n",
    "    \"\"\"\n",
    "    So far assumed k = 2:\n",
    "    \n",
    "    Converts an integer between 0 and env.action_space.shape[1]**env.action_space.shape[0]\n",
    "    which is (n+1)^k where n is the number of tanks and k the number of trucks.\n",
    "    \n",
    "    return vect_action: a k-dimensional vector with components in the range 0,...n. \n",
    "    For k = 2, vect_action = [i,j] is the action of truck 1 going to tank i and truck 2 going to tank j.\n",
    "    (i, j = n means staying at the depot, 0,....,n-1 are the real tanks).\n",
    "    The associated integer is i*(n+1) + j\n",
    "    \"\"\"\n",
    "    nplus1 = env.action_space.shape[1]\n",
    "    k = env.action_space.shape[0]\n",
    "    n_actions = nplus1**k\n",
    "    \n",
    "    j = int_action % nplus1\n",
    "    i = int((int_action-j)/nplus1)\n",
    "    vect_action = np.array([i,j])\n",
    "    return vect_action\n",
    "\n",
    "def action_to_int(vect_action: np.array, env):\n",
    "    \"\"\"\n",
    "    Assumed k = 2, so vect_action has 2 components\n",
    "    \"\"\"\n",
    "    nplus1 = env.action_space.shape[1]\n",
    "    int_action = vect_action[0] * nplus1 + vect_action[1]\n",
    "    return int_action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[2 2]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "int_action = 14\n",
    "print(int_action)\n",
    "vect_action = int_to_action(int_action,env)\n",
    "print(vect_action)\n",
    "int_action = action_to_int(vect_action,env)\n",
    "print(int_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dsalgador/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "seed = 42\n",
    "learning_rate = 0.01 #0.01\n",
    "\n",
    "model_file = './final_pgmodel.ckpt'#.format(learning_rate)\n",
    "graph_file =  '{}.meta'.format(model_file)\n",
    "epochs = 100 #2000\n",
    "batch_size = 50 #50\n",
    "\n",
    "summary_freq = 100#np.ceil(epochs/10) #200\n",
    "\n",
    "\n",
    "hidden1_neurons = 100 #100\n",
    "hidden2_neurons = 50 #50\n",
    "\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "            #inputs = tflearn.input_data(shape=[None, self.s_dim])\n",
    "            tf.set_random_seed(seed)\n",
    "            # 1. Parameters to determine the NN architecture\n",
    "\n",
    "            n_inputs = env.observation_space.shape[1]\n",
    "            n_hidden1 = hidden1_neurons; activation1 = tf.nn.sigmoid#tf.nn.elu\n",
    "            n_hidden2 = hidden2_neurons; activation2 = tf.nn.sigmoid#tf.nn.elu\n",
    "            n_outputs = env.action_space.shape[1]**env.action_space.shape[0]\n",
    "            \n",
    "            indices = [i for i in range(n_outputs)]\n",
    "            \n",
    "            initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "            # 2. Build the Neural Network\n",
    "            \n",
    "            X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")\n",
    "            #y = tf.placeholder(tf.int64, shape = (None), name = \"y\")\n",
    "            \n",
    "            hidden1 = tf.layers.dense(X, n_hidden1, activation = activation1,\n",
    "                                     kernel_initializer = initializer)\n",
    "            hidden2 = tf.layers.dense(hidden1, n_hidden2, activation = activation2,\n",
    "                                     kernel_initializer = initializer)\n",
    "            logits = tf.layers.dense(hidden2, n_outputs)#,kernel_initializer = initializer)\n",
    "            outputs = tf.nn.softmax(logits)\n",
    "                   \n",
    "            \n",
    "with tf.name_scope(\"action\"):\n",
    "            # 3. Select a random action (where to go) based on the estimated probabilities\n",
    "            action = tf.multinomial(tf.log(outputs), num_samples = 1)\n",
    "            #print(tf.rank(action))\n",
    "            #action_onehot = tf.one_hot(indices, n_outputs)\n",
    "            #y = tf.reshape(action_onehot[action], (n_outputs, None))\n",
    "            #y = tf.Variable(action, tf.int64)\n",
    "            y = tf.reshape(action, [1])\n",
    "            #print(tf.rank(y))\n",
    "            #print(tf.rank(logits))\n",
    "            \n",
    "with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,logits = logits)\n",
    "#             xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = y,\n",
    "#                                                                       logits = logits)\n",
    "            loss = tf.reduce_mean(xentropy, name = \"loss\")\n",
    "            \n",
    "tf.summary.scalar('average_cross_entropy', loss)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "            # Optimization Op\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            #optimize = optimizer.minimize(loss)\n",
    "            \n",
    "            grads_and_vars = optimizer.compute_gradients(xentropy)\n",
    "            gradients = [grad for grad, variable in grads_and_vars]\n",
    "            gradient_placeholders = []\n",
    "            grads_and_vars_feed = []\n",
    "            for grad, variable in grads_and_vars:\n",
    "                gradient_placeholder = tf.placeholder(tf.float32, shape=grad.get_shape())\n",
    "                gradient_placeholders.append(gradient_placeholder)\n",
    "                grads_and_vars_feed.append((gradient_placeholder, variable))\n",
    "            training_op = optimizer.apply_gradients(grads_and_vars_feed)\n",
    "\n",
    "                        \n",
    "# # with tf.name_scope(\"eval\"):\n",
    "# #             correct = tf.nn.in_top_k(logits, y, 1)\n",
    "# #             accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "# # tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "                       \n",
    "merged = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "        \n",
    "if model_file != None:\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From https://github.com/ageron/handson-ml \n",
    "\"\"\"\n",
    "\n",
    "def discount_rewards(rewards, discount_rate):\n",
    "    discounted_rewards = np.zeros(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step] + cumulative_rewards * discount_rate\n",
    "        discounted_rewards[step] = cumulative_rewards\n",
    "    return discounted_rewards\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_rate) for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean)/reward_std for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9999"
     ]
    }
   ],
   "source": [
    "best_acc_val = 0\n",
    "acc_val = 0\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)   \n",
    "\n",
    "n_games_per_update = 2\n",
    "n_max_steps = episode_length\n",
    "n_iterations = 10000\n",
    "save_iterations = 100\n",
    "discount_rate = 0.95\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        print(\"\\rIteration: {}\".format(iteration), end=\"\")\n",
    "        all_rewards = []\n",
    "        all_gradients = []\n",
    "        for game in range(n_games_per_update):\n",
    "            current_rewards = []\n",
    "            current_gradients = []\n",
    "            obs = env.reset()\n",
    "            for step in range(n_max_steps):\n",
    "                action_val, gradients_val = sess.run([action, gradients], feed_dict={X: obs.reshape(1, n_inputs)}) \n",
    "                vect_action = int_to_action(action_val,env) #HERE WE CONVERT FROM INTEGER TO ACTION's Array\n",
    "                obs, reward, done, info = env.step(vect_action)\n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "                if done:\n",
    "                    break\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "\n",
    "        all_rewards = discount_and_normalize_rewards(all_rewards, discount_rate=discount_rate)\n",
    "        feed_dict = {}\n",
    "        for var_index, gradient_placeholder in enumerate(gradient_placeholders):\n",
    "            mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index]\n",
    "                                      for game_index, rewards in enumerate(all_rewards)\n",
    "                                          for step, reward in enumerate(rewards)], axis=0)\n",
    "            feed_dict[gradient_placeholder] = mean_gradients\n",
    "        sess.run(training_op, feed_dict=feed_dict)\n",
    "        if iteration % save_iterations == 0:\n",
    "                  saver.save(sess, \"./pdenv_policy_net_pg.ckpt\")\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#         train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "#         val_writer = tf.summary.FileWriter(log_dir + '/val')\n",
    "        \n",
    "#         init.run()\n",
    "#         N_TRAIN = X_train.shape[0]\n",
    "#         m = y_train.shape[0]\n",
    "        \n",
    "#         n_batches = int(np.ceil(N_TRAIN/ batch_size))\n",
    "#         #print(n_batches)\n",
    "             \n",
    "#         for epoch in range(epochs+1):\n",
    "            \n",
    "#             for batch_index in range(n_batches):\n",
    "#                 X_batch, y_batch = fetch_batch(X_train,y_train,epoch, batch_index, batch_size, m, n_batches)\n",
    "#                 #print(\"Xbatch shape\",X_batch.shape, \"y_batch shape\", y_batch.shape)\n",
    "#                 sess.run(optimize, feed_dict={\n",
    "#                                     y: y_batch,\n",
    "#                                     X: X_batch\n",
    "#                                 })\n",
    "    \n",
    "#             if summary_freq != None: \n",
    "                            \n",
    "#                 if epoch % summary_freq  == 0:\n",
    "                    \n",
    "\n",
    "#                     summary, acc_train = sess.run([merged, accuracy], feed_dict={\n",
    "#                                         y: y_batch,\n",
    "#                                         X: X_batch\n",
    "#                                     })\n",
    "#                     train_writer.add_summary(summary, epoch)\n",
    "\n",
    "#                     summary, acc_val = sess.run([merged, accuracy], feed_dict={\n",
    "#                                         y: y_val,\n",
    "#                                         X: X_val\n",
    "#                                     }) \n",
    "                                    \n",
    "#                     val_writer.add_summary(summary, epoch)\n",
    "\n",
    "#                     best_acc_val = max(best_acc_val, acc_val)\n",
    "#                     #print(acc_val, best_acc_val)\n",
    "\n",
    "#                     print(\"Epoch: \", epoch, \" Train (batch) accuracy: \", acc_train, \n",
    "#                           \" Validation accuracy: \", acc_val)\n",
    "#                     if best_acc_val <= acc_val:                        \n",
    "#                         save_path = saver.save(sess, model_file)\n",
    "#                         print(\"Saved model with validation accuracy \", acc_val)\n",
    "#         train_writer.close()\n",
    "#         val_writer.close()                            \n",
    "#         #save_path = saver.save(sess, model_file)   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from pdenv_policy_net_pg.ckpt\n",
      "[0 4]\n",
      "[ 19.08499034 167.27643223  56.98749111 345.96423565 138.43103839]\n",
      "[5 3]\n",
      "[  2.58499034 163.27643223  46.48749111 391.96423565 104.43103839]\n",
      "[5 3]\n",
      "[  0.         159.27643223  35.98749111 437.96423565  70.43103839]\n",
      "[0 4]\n",
      "[ 53.5        155.27643223  25.48749111 353.96423565  36.43103839]\n",
      "[2 5]\n",
      "[ 37.         151.27643223  84.98749111 269.96423565   2.43103839]\n",
      "[0 4]\n",
      "[ 20.5        147.27643223  74.48749111 185.96423565  98.43103839]\n",
      "[5 3]\n",
      "[  4.         143.27643223  63.98749111 231.96423565  64.43103839]\n",
      "[0 4]\n",
      "[ 57.5        139.27643223  53.48749111 147.96423565 160.43103839]\n",
      "[5 3]\n",
      "[ 41.         135.27643223  42.98749111 193.96423565 126.43103839]\n",
      "[5 3]\n",
      "[ 24.5        131.27643223  32.48749111 239.96423565  92.43103839]\n",
      "[5 3]\n",
      "[  8.         127.27643223  21.98749111 285.96423565  58.43103839]\n",
      "[0 4]\n",
      "[ 61.5        123.27643223  11.48749111 201.96423565 154.43103839]\n",
      "[2 5]\n",
      "[ 45.         119.27643223  70.98749111 117.96423565 120.43103839]\n",
      "[5 3]\n",
      "[ 28.5        115.27643223  60.48749111 163.96423565  86.43103839]\n",
      "[5 3]\n",
      "[ 12.         111.27643223  49.98749111 209.96423565  52.43103839]\n",
      "[0 4]\n",
      "[ 65.5        107.27643223  39.48749111 125.96423565 148.43103839]\n",
      "[2 5]\n",
      "[ 49.         103.27643223  28.98749111  41.96423565 114.43103839]\n",
      "[5 3]\n",
      "[32.5        99.27643223 18.48749111 87.96423565 80.43103839]\n",
      "[2 5]\n",
      "[16.         95.27643223 77.98749111  3.96423565 46.43103839]\n",
      "[5 3]\n",
      "[ 0.         91.27643223 67.48749111 49.96423565 12.43103839]\n",
      "[0 4]\n",
      "[ 53.5         87.27643223  56.98749111   0.         108.43103839]\n",
      "[5 3]\n",
      "[37.         83.27643223 46.48749111 46.         74.43103839]\n",
      "[5 3]\n",
      "[20.5        79.27643223 35.98749111 92.         40.43103839]\n",
      "[5 3]\n",
      "[  4.          75.27643223  25.48749111 138.           6.43103839]\n",
      "[0 4]\n",
      "[ 57.5         71.27643223  14.98749111  54.         102.43103839]\n",
      "[2 5]\n",
      "[41.         67.27643223 74.48749111  0.         68.43103839]\n",
      "[5 3]\n",
      "[24.5        63.27643223 63.98749111 46.         34.43103839]\n",
      "[5 3]\n",
      "[ 8.         59.27643223 53.48749111 92.          0.43103839]\n",
      "[0 4]\n",
      "[61.5        55.27643223 42.98749111  8.         96.43103839]\n",
      "[5 3]\n",
      "[45.         51.27643223 32.48749111 54.         62.43103839]\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "frames = []\n",
    "n_episodes = 1\n",
    "\n",
    "system = PDSystemEnv()\n",
    "\n",
    "model_file = \"pdenv_policy_net_pg.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        saver.restore(sess, model_file)\n",
    "        for episode in range(n_episodes):\n",
    "            state = env.reset()\n",
    "            for step in range(episode_length):\n",
    "                system.state = state\n",
    "                img = system.visualize()\n",
    "                frames.append(img)\n",
    "\n",
    "                action_val = action.eval(feed_dict={X: state.reshape(1, n_inputs)})\n",
    "                vect_action = int_to_action(action_val,env) #HERE WE CONVERT FROM INTEGER TO ACTION's Array\n",
    "                print(vect_action)\n",
    "                state, reward, done, info = env.step(vect_action)\n",
    "                print(state)\n",
    "                #print(action_val[0],emptiest_tank_policy(state, system))\n",
    "        env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAhsm1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9OSBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MTAgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAt5ZYiE\n",
       "ABD//veBvzLLXyK6yXH5530srM885DxyXYmuuNAAAAMADN2InuDwrXQ9FeAAIdqvwZmf4AJmCqDG\n",
       "ttMWJWxdvy7tnT+Rz9wyhVeMFMVPTOpJQqtDr9jXJX/E5m6Zk2FMJ6dNhtnSyxBboXqb/s9fD1po\n",
       "LkxHc9HtfVxbZz2KpccMoFRkX7VxBjghdRFz6gJTkY3xsfj4ZJzyTYohsc8EzzQc1QBZifHYacAE\n",
       "v27mHi4WNFDfFp9zIHJE33dKtqAM3PH5B9aYCza7/OL8WbGpsD4RF9FAwah9zWG9PWwJMWztq3z7\n",
       "zyt9qPehuzGjBWs2pMdNG1DO3RWpW+DM+edevms1dYQBGzbdMHKcgtzS0+3yDyr4KCqsvcUACyvY\n",
       "E0Kooj8P373lthCiNXFyaUqTZoVsN3Plc2ph3eNEaC5W3y7LmE4vBd1RSOjOJJhoxev9mXRouS5+\n",
       "AKRM8/lIAfZbZP6lWiEcj4TgSEOl1FjQy9NDjkMU7J5SbdC4tEYFCnQDmL9/MACbpVEPHinlyHqY\n",
       "Edg1WdFwNDmq2i+Ql9kLe5IL18I3YfDooizmIsQs0WhjEdxnGXpqfSAiL6Ps6QcKNH5cpoZyDjhy\n",
       "7s+qPQssEnLu2i5M6Nv9Lyb96wiH2JGTp2c5M8wJLj1/51ASfms9QhZasNpolmYYbZgW7LcjbfaX\n",
       "Z1JVvzE3XOfs2goyMJ0npxvzUKJruj5LsRClIo5kmQDIFWfF92QcAqiu8OC1x5ESgdegn0L3k6st\n",
       "UPhpY56Ez8e+gy2iNHo4VjDmqpQNEuUFOXHnRqjUhkiWlrllSZ5sGCssF/7NFG2y47FqZPSXtNwS\n",
       "W1tsANPGIuuaf2YN9RhudMwgIVYpzcVAEutxzHMHgnysJsQvHqbhxnEMtCRs43707bvRa9Ftq+b9\n",
       "XaTSPoiGjDRxSJaGC+NG+NvC0aOcL7z9iSmRIR1O7SO8SJCtd7Fr7g4oPKloLO0XeVfz0JzeX2g9\n",
       "1+jhOId5KaRPMB+DEbtl1m/r9lg6PwN2dAYG+aeobRmKgukde0hqYL8dtNbTeYGY9ddjno6z9n3L\n",
       "TbBWUIEWqz5t5w393njiVN82yQ+jDC+Kqt3fkXJ/ucz+885AEdGW7Q6d/xnpKO/hPDLlpdid9i+p\n",
       "Go3Fv19yQ8pJ1ZuyzaaVnPlpnBAZJen56kMp/PHDlCUlZe5k/7XBNUU3GQeJcXl9T2iBdYCqpDLk\n",
       "Wtp4D4lmaYLaQyVZ8Mo34VGFjE0p8oUU5bbObn00u2tElLWZ2zaVsuPb34ZorbJ8VYHSBmcnVyFp\n",
       "y0/lI3jjtzHD9TOwCJuSHqT6XEvkCxsUlziDwBLBMFo3umne/tLT1XWoog2vTnpRRN6w1rMX2me/\n",
       "tMTqxTCl1L2GgMtSoI6bVgATe2ViuirxB8PlCBkvCIrd9z2+cnhh2lWdKvsMHhbTUoubmN6GMNLc\n",
       "nrL+iZVF7tNQMOpFGRlWWIFuhMNZPQd25W4TjNQq2Q2FVcVeYN3j+tS1Ldv/V//1wKN08z/YUSmg\n",
       "eEKNA8Za1XSXzycCrj8O71HILcgNjNEX+SUP4yT/BcuyEWpDha8ayNeWtT8A1U67VgLYBxJvPpFg\n",
       "oQZZMBpbK35rJTGldaULoE1HYDPdSwwwSYNXmA0UR9rm6t7VbJsi4Wi628Ef+ss4FTreAtaoP/Vn\n",
       "veXa2MOnVdHyjw+I9F/ZuFWHpRRfbwRc7q+9M4A7YH442kgcvBLAmQtfjc7xbFJYSv0F6B6lcrt+\n",
       "k/vabsW/meVkijxFaHmF4BCWumG9xkrZI9uf64+TZJP/uL8vmZDUkMVhNNPtavUtMJ0vqqPRcEPR\n",
       "F84ry2DEh+/hec5uCB6JAemZPqMxwrPRfSr5e1Wj2RqIaj+5ckKv7gROK0XaIfcUDQ3GnqVd/rBg\n",
       "Mpg+GCMsTrouRZ8/wv6kopKDGMIJifrhkuG5u/+lR+SUp+wEjWuWhGdORqFUYMCY7AyaKXQHUFjZ\n",
       "gxwBnsa8hdt/LGfA5uO2X5CP/tZwwQzfEV0LoI7DHstewenOmmbcIgFoQK0GAW8pXE+FSj9yDI2D\n",
       "f2qh8iCN0dCAZHl+T8TvUX2/56sIY7E7UnG7/zm5YdMx6n0g5ripLMGQjuiILTgrTTajcG4xOlhH\n",
       "aFoIFMe1GENXsEpstde5o87bTfWzfrDBG/HYtD7XLcg41sX68rv27w6sAU/h43wlVOwjY1Y+se/7\n",
       "cVULVnwy0uXxQ9h+z9Edc+N5BkqbmCYjO8fu8Du8QXorijyIs+fRarAhkXZo1RGGWjPV7dT/7OQg\n",
       "/PL/VkNoe+H/bp9Lct0sRytDcfrL2R612hT6Rlq1fl4bq/Eb9fgoBYBeQAjS4cASXZA+myHDlxhO\n",
       "u3cDImdxE2LoQSRxfpAiUpKyB+yzRrwlMftOq6yArXz9atzpEhAaEyrny+ZLXoHLI+i3be5Yz2Wx\n",
       "P3sxMltzYoUIXLAsM8YSpkoULZbwAY7Z+XL3OJXq999Vx5TxODDQn9KU0a+LmcKMhNw8vs2neQu0\n",
       "a7cYQR5y5KjscK5Gy24j8D/MQKjfqcdn/1f1mUo6NyrgYbbQd0aYDsH0dzR+zb/WZ3pJ5fgxZ9sT\n",
       "2xeJiaGeh4dVxqK5sFO+DOpJJb9zIukVSsdfX7TrsWbZLaXQK49LBVGClhxSx/jNt8TlgFsugkrA\n",
       "VWEVdOZ5Zo3fdFY1QKYpwcNROcQAVz61jF5bDv3erljkghv/1g/y7o0PVbogxXf91tASPhuLm89l\n",
       "k6Lwfe3FfUI/+qLw3o7gwhTMwHv7wlebAJe4PLIp/GwsyCbtuHnLJ6INg8Ky4CPb6HTh/yzf8vWH\n",
       "WqQTPpmyJieyJmt3OKUG2RDrkVYoeTgqwZKhLHjhG9si8QDhiViqrEbK/JpfA/S8cdTtmqWXeifv\n",
       "6GLt/+3aEqRS+gDKX15PPUtHF5mAQPb1cGLEDFbH99EIuqkgr4CXseoawPQSFbEaowiik5LjhCoH\n",
       "Zk4/4msF3xRBUQRMSNliC57t3oJPMOKjsOnIolpH6KrP4QVHdCMn0DGKk7jDrGaF9c8aofGDuHjN\n",
       "OeKksUwjCAUm6HcwWe7ffEb6DzFnhCwSIeSd8obygvBX/gXG/t94bREooNp4wAAnzfFlJsYjk3QL\n",
       "+NaL6NVYRexcjxLW1d3oT4Xemo8p6YtZH3gjpO/OHi8tPtN5lx1XFQBfilnNwts2V4hsW6rhWNUN\n",
       "KbZeflQhz2FB1nnaKFlZF3mi/ROKJg1XV2IQYphL4+oHVDOFRQs4YYaDCjkRIayhyR0IMii+C3cq\n",
       "+TT8sU2mWw3ZxlP4fGJftcAgfB58NzCZwL8j2ms+6vTGDAE073bqOcr9CXMImOYCbszyB96y97kd\n",
       "pS9EiQWBohbkYc06M5Ksa7gy7ZXWdvqUuUEhImNG9WDGcDQgW0M3AmEA0tsyUMf6r3ysZf4qCA0Y\n",
       "xK9rKAXB+bUxfeJQy1wUPS+/np1qFvGqBoRAZbUxXqAgadtriMxUj0U5Oo66CSc+C2w0MVtO7dHi\n",
       "UVY22VIGu6v9jqOdaZuyRbgjMkaxA7mfgSch4r7AdIdlqKDCFB1w/LX93KFboenB+GBUfDRxGfwf\n",
       "M5FRjqfAfxHrZAHydB18wSpFtM2R6ZRUAN+tPqhXISj4MqO810464iNAj9fXhKwy90a1Codk5Lgp\n",
       "uBKQZr6dCCWdJ9CpZrmSpnJb13QOaNeWsq+tDrAX8rxhgA28QtKZNisAxp6nZ7YO92NnqepA5mhp\n",
       "joUp+wOL5tcOhIT071yZhuzadqwobUn/6gKLQ41Vz1ZZMZeG8qr8NW7u9muHdKCV3BPnQLgmAs8D\n",
       "yeEzop182GwJINLTULF88d8Ga5q/lnea7i9efI9f+4Nf0lM+VrXjFyLMfTGXmGtwLyS3djHjSauh\n",
       "cPTNoua4Y/gWPLIp2+rW7jjQchmlAAADAAXVAAACSUGaI2xD//6plgEFyJaAV2P8xlSaESu/EJ8Q\n",
       "7zj443gtCCkLEHSTKL4J/Xd66TZ+BjZMqbZB8mcniuoFYSZuQ1jf5dPXdYMAoZ880mMMz05LIdT6\n",
       "5w/btcVMNp1eNSa+8OgBdZ0qiDVPfhWEIopKKCkivMSc0KiUSx9Shg3YhmaHPmZwkueleQHahuri\n",
       "UVwjfEL+D2znBCp8L0Y3pzNG7L6torCXxivmewu+9de5o31VtbtESG6QD8wwcW1i//kbhCEUzbNg\n",
       "wrFt0iD/Z5++Iv4UK+gV20vIBW6z1ZzrOSO8PHK+oTo3Dv/fq8GzpXdOLeRvQGBjxzGr4Kuwoop4\n",
       "2Hf+BlKjPY9p2UYnXyxo81NdfH/ZiICIc+bb63DssoKPbaQIFsYh+/dfNxO7g03Q/3mntevMTV0e\n",
       "/rUCScp2X2Q9dEn3hcQzYYGEe9B05YkYbmqoxegirkjXMIUTNUTplHp2HZ1b4lrREUwYJhRKZ22Y\n",
       "Yql575N13EM+uK/X0Gssa8gLecReAHdPJB4qKENfZZcVBiGa+IqJKnB5CknEWb26f3/YdZ7I9oGJ\n",
       "382oJfv0D6De6L0PCFBxiPt8HDumq/Ir6a2z80IclhATbCtmnt7bxFEu8Pz9BaCdNHsWpNRv0Li2\n",
       "9v4vJKMxEbFpWg41oBYytNxLQOxdjVlG1WHS4zWwdgovqZG4FLQY/edhL/gehleWEqZsnFrTZXh3\n",
       "JngiCx4vkUwUI3NhEBCqloT+AS3zETKZq5Lo3ZzgpeR24EN3BHnrjUsU/EpRbAAAAQJBnkF4hv8A\n",
       "cPumFYDsUHWakdkpNFgA5ryxZmOroYlsgyHfkzP2F7umSN5q7KsPMEd1HXois/vn8Qyj/87L8m1r\n",
       "Mf2j9jxRJN58xIV+9+dz6UtkMzgI/hU6sm1kihKxbYmfmbQBKhaYRJMn5o5NrHzej0tFjdDeYxP3\n",
       "Uum5EJvp3HewNFq8O90NiP6nDzZrPEc3iJ2wbzUIHJGodY8P/GWh2qkEZqFMSqNMorsKNcOzdDh+\n",
       "ObG4RcUs4+zGeyx9HQyxrOpoL0Fyl9U7iJBcrAxtpiKJdf7yWoo6KjeEddOyjSRXw4t7kmIztGMg\n",
       "9+jfGt54frb1uZkQa/IzI3V8HbbmKSkAAACjAZ5iakN/AAOJ2sIw323ibntfn7NUAF4TBzdaox9E\n",
       "j3g8HxZ5RUzEvKU7lAyW7WuhiSR7M909/12o7z3PtYXJ0k94T00Sw0HjH3TEmLW4SCN+i2TgXD9/\n",
       "BpavwEkm79lz2G5K6eRSPCkj49ic8FisHfxK9Srn5OlsHxQyfsFgjkvdTeQHw8ygFs8VdD4D9/s3\n",
       "7a5GjJ2n57bbYF4WKUSkDLDggAAAASVBmmRJqEFomUwIIf/+qlUAAFC+L16sNnsLJGCajQ+4jEpG\n",
       "FggxB4/4J3PgCS9+BnMOaX8335AI/jS9YoVlLwCSwElmERbYQw4cS0Xqonb4TcXS+frDYj/k3QUq\n",
       "eKG38WlBD2pMPjclFyB8PgpksPGPXWtEkgT75F1P3OjhWVXP6bC9Oh11SNL3VJjIFGqpAaeThHXq\n",
       "0fkAtZDpMHEcShdfjA2EMaURxPs+p3G5Vu+5e1PtezkUtFUtrt88nGIcyujMmIELJqL/B2A03yLT\n",
       "5fl8oKcG2dETwphc7Dh2QS7/O3/5RL8c7YMyQcF+nvbqKTErUYu3ewjZM55DdWpz/CXFtIkkYfkX\n",
       "B1UgQwY6MPKV3ZO963RD/bwDCLTcC/avCP8ugZV4gQAAAOBBmoVJ4QpSZTAgh//+qlUAFKEKrWYg\n",
       "C8QWdtMHLXjZe4s25K1HGt+h0kEVnQ6vPTeFVc6XpB5868CXZNFhAEPWCIeXh0M2Jj2c+qExtxG7\n",
       "Yf3lM4g+dYQvPThpw1k7UOs9H3JccgigOIkbzZMHzCTcqNUYJv9+fM80D+PMUwiZ8Pq/AHjDqvQV\n",
       "EKa5jJ0DRQi+qts9Sw/gcCKc/WEJMiOd7LJRhv+YOEwF7ZmpPAhAWxaSY85H36U4VyjPJl64R9Ef\n",
       "W4PRNWyPULQt8H2YtD9+3hG71P/kOXzcLgPQGeIu4QAAAP1BmqZJ4Q6JlMCCH/6qVQAUv4vauqfY\n",
       "x26L/ZkEZsgGou8s5CrsMgn88wuhPGh2t2KcHoGk1v8djxSTOoaP9WU2J/cdEqAIl+BOs9ARvvSK\n",
       "Bkv8aagMfQaACMelopp87f+0xOkfi7/7XTHyDACK9NxKjM3noOsyhJeajwYptCjt5nbXQq877Y/b\n",
       "+XwW4CFVd+03PPSlDkjF4jW7B2Xwxk6O2fzWQVznQ1uX8A43v84QRpOEVoJO7tPc2i/k0En2k0L1\n",
       "J2tr0gvPq8VXKXLAN0DFoG6Jimihm6QulpFTzBVpaN+qNaeRZpvTyZCmlE0c1B2X0DM13+vhS7ST\n",
       "sCahAAAAy0GayknhDyZTAh///qmWAFBZffWMO1f12BXgjzT2nte8Z9mosIAjWDnqy+k4aFoI5NC2\n",
       "gPGhyrsu/4L5hoOvBP5L7dX31oQF6ZV93sv56UWRC47veB3fjZOrRlLr55PKE+qqDgzde5QrskP5\n",
       "IV2BF0zFfkUwBQbjcISqRhO4VeSftItdXcPgnExCLWS0C19R1/9BnA8Jw4vEr0o2rta3/4NlczhT\n",
       "KWyIpVcvX21UH8ZIzrHbMXcHbR1AId1zPngK45ReYbYvd5Ua+MvxAAAAekGe6EURPDv/AABQURvV\n",
       "PbW3TgxdtoFCAOmqvPXWhK4lZ2kAoA9PvnljFmzjFfYcY8czlIoV+olOtjwuugASx4+7yxpY00Ql\n",
       "ICFsmn0CAlmQDCnJjI1kvZhQwywFYoeqGvDZs0q8qT9RiCamazhBx6AyORFM8dVFKt2AAAAAgQGf\n",
       "B3RDfwAAcU97WIDX95421uXfNuCadH8h+DDDbh2e59+8tGtf52hQAXr60CNc2o4K5e5yLU1mnWvl\n",
       "ulG6nSpNF72vwI8EiYbvyNYBgQJe9zGYF9Fy/L/7LSaRoY935HFHzicgTWKWL52h5dQKSJJQDfiS\n",
       "hmihYRF1CSdUmFEHLAAAAJcBnwlqQ38AAOKbDxvzV+NduOxqmkSQt9J5dkL8XvDENZh4AHD5ZN1d\n",
       "nmohuJaBFfPjjEZvK/KgMeFd2RQnqGPAfXv7KNfgAFoVyBM3wti9V9uBfwDHAmYi4PVP0P3u4nwz\n",
       "bAqzyHzVCmXVDsK2Ho/EhMMLKdMrt7AtbYF16ITYGf5J07Dp+0fNYE+qZE8YOdv7nRzrKHIhAAAA\n",
       "z0GbC0moQWiZTAgh//6qVQAAFL+L16rscBPFkgOwLmg0wshBIzYPUUduZ7nkAGSXMob+7bkgQDoq\n",
       "a4z88i2AaeL94dj/7PazIpaD70XP//+JDFEl6Z3FOR/E7pvNptd8Ys06EKJjA1dliAoAoBQbUH42\n",
       "nzL921+BJe9Hf6dAm8OccifWYN5dYVktZQH+YEROdDlye7WGQXqEhfX36mESWuB/a5Y5oro+l8g7\n",
       "y+0i/fE48ihe9gt5qSUJPhdHOzGQRg3AXzZbsrPz+Zf1AFLYEwAAAJ1BmyxJ4QpSZTAgh//+qlUA\n",
       "FKEKrWMQBeILO2mDlrxsvcWbdLNs5syT+i92O1Vxvjvb91WBDbgpcX+se5qa1W6H7u3BvSiEAM/X\n",
       "UKZYIUgo/cqo/Hd8ef5L1/fUbo4ig8iNvG1CkHRPtM+bLK0KJV3DIXsbIeGV51F08Mdnkqy6E5EP\n",
       "I+VfypIhf2wEp1J1ZzQZ7GDC3giZczf/IDCgAAAAuUGbT0nhDomUwIIf/qpVABSmXnXSn6tYXBvV\n",
       "F2uIMG33ZrK/MuJZUQBwxkTlavP1yKQcARQadNgw7mwYqGVHlDwCz1BFKGLMHNDOVHYeo1CcKkbf\n",
       "onTOP7weTV/w/2hXipD/6g65cIV/FGB/0wgvRRTTyH6g4CGY1iJuX6LY+0gfFSBgsxVSEFeySWO6\n",
       "3xOkqchI3b67MJDfvmsAxuZoMVcbQzy0FFOqRrC6I9C4bYYdRWeaNOXJvw8JAAAAeUGfbUURPDf/\n",
       "AABuoZAnpTCjjn1q3/WXJrAeDHr2jhW3hPhDt31NTFpdXCsVbcotyvnuXyD/M3KSAT81T+PMLd8P\n",
       "xzggr3YeiNqL9/0Ya2QpqqArz8MshdVqLhjKVghZKa1v3Ne0cj2qgsFPspiOQlyyzfrVdhGT/wcA\n",
       "AAC1AZ+OakN/AABunTn5AmxV1kTFkPREYtMoPPrbRH9UpM3O6HNJcEKdQAUEARqPtIs6UXwixFVV\n",
       "5/mdC7wsPXR5CvgxHJEh8jioX5vCUQE9uCiLtaBWOZys2XTmgODybHm9QJsgaph4eT6SvAzr2SgZ\n",
       "08QmVeu3oweAZuVjqXJxbMV0t8q1j3AjORJCFJPXQhIFv8eXgwMtJJ2OwS97WFA+fnoxjBXpSRAu\n",
       "kAgLbbXtgcj76K/FwQAAAJ1Bm5BJqEFomUwIIf/+qlUAFLPPOuin3sAABE6ZasMQg7FKiC/mOi4N\n",
       "cocV94alAAMIzHCjCmIRqxKB9FLy9oB/4jAPWU9/8Y8GuzIPZ+b5lk7v7yg1ttVXmf7j/oOaV0wh\n",
       "afwfiE3/7Wf/7kUHBQdrA0ryMHBO1CYDIp7VVLdYTK1W4tXS/MEk8k7L8NqlNl4AV+r8c85dcTNb\n",
       "7AmAAAAAg0Gbs0nhClJlMCCH//6qVQAUpl510U/VrC4N6ou27drsti6wN8ehS21W5ES88iC29We4\n",
       "APkpUICRHEVY0jh5inF057lMl1x4mAUOjCFb1ptrH8RzJz3MGXxNSgZ65CXHnlCGb3cI3+CX/XtX\n",
       "Xr5R1ZS+ailTEy3dHY/sNNecgCKtRTdIAAAApEGf0UU0TDf/AAAcTtYRhv4uRna5pFlvEbLcgEvk\n",
       "VVP73eeM8OziWN2ZnOTo6vcAhQAsdsNeBf/uruDevSpk42D0KSza7bJjSGiUV3OwiHkRmEWn4tDY\n",
       "EYtU0yyuqbZDPWM9gJ9OsRV3rS2vFS+v1QH9Z9e/cIlgFIcgaDQvF6iO27il7ZNMtk6ptPrz37d0\n",
       "amh7CwcJirCXEj73SC4IDdI8GGWBAAAAaQGf8mpDfwAADiSTGRUArllBjx8WzHzdee1ncEkQANJJ\n",
       "6M6o33eH5WpjnA7B8aCPR0CRUA92bSuwrZTeEdhjVGyNVQxBYzVIFWicCVZ0e1CC4uGJ9IB/aQP0\n",
       "XS7mcJgzecNp3XLETNgXogAAAHdBm/RJqEFomUwIIf/+qlUAFKZeddDNrgBATZtYfa76beZx/40q\n",
       "dtnymsjoE6LmZgrZoHCIYEcI5GtMjhULjox4xTytRcxauuDcOtd7mggVXHCNhCUeObZC3EgOGkTK\n",
       "xLreKCilosFit7PukZRQIxBPqbaplyp+2gAAAIRBmhhJ4QpSZTAh//6plgBQWX31gw8MogVbw8cn\n",
       "XYAeCTto0IX8J3sBTR3wks6j5PTW0UQAayWKOVUYlMpduwzqNmmCmneZBgHI5IlfDOB3Ho9xZbK5\n",
       "92tDmLjBV3xUYSeOr+wJcJ3IcW1znB+T9xOpH1H7Y5BWCCqp/0zmkIACwVqmW6cAAAC0QZ42RTRM\n",
       "O/8AABQN6QprHsMnEAGgpX5oFshnGzOvbyfecgy4RxJg1HCRLxdctF4aVzfr3ZwkYe4g6y3iIG6o\n",
       "3vvDrRgoiYnUMhDFHB/8Lv6/4AlBD35qakuUGyJJnqA/Q2y7krbY3Knc2CMnIDPiVGJubTifok/+\n",
       "+19gzCW4oyRljUo/KaFjDn+g5qnmVGNUFXAnhd8FH7ix9WPyrdm4/TGCplWP3UlpQ8HJc0HJ3qDz\n",
       "YS/wAAAAiwGeVXRDfwAAHQPfayJHEhE93VVf4zbPdS+xmzjRNirrImNMNzJdLJMSCxWHAmAfAByJ\n",
       "4OyA5Cj/VkjR4y2BaVHvlbhDHoR/vKDerGryNalXrRqN5oTypRNL0trOR036hf0ZPsNfZYEDytNB\n",
       "tzK2yd4q7giT0DCzwsMTJukTkvc2x5zQWAlxFYjmuskAAABKAZ5XakN/AAAc/tYRhsPYz+V5QXWg\n",
       "BKhnpXBlegrI/1RbvlTW0k0SrI3/V2cgwr6MI0uDeiHRsdMO3KyDi1jPQD1Q+HOzSQrs5r0AAACK\n",
       "QZpZSahBaJlMCH///qmWAFBZffWDDwxscYsmZHexYMnp2edT+AqT7f3MykUAAE102n4Bi0IPjjZq\n",
       "3HV21uuPQk+Y00bPcfQFI3KR4hjllkPMURSUJC3v0x1VpHP+jsvF2WFdAggAo4AtB5n6FDKnf3G4\n",
       "yIeHmY3KVq7kGEFctIgXSB/8hS9qmWScAAAAWkGafEnhClJlMCG//qeEAJ7UINQNOJB8juN07vID\n",
       "4kPpJvwAMjHJOXWAEcOIdyfIX51KAVBx+DYinKnXvv3frglwIjnI/jCYfx6Q++0oAVMjDpPpyOok\n",
       "MdVbsQAAAHRBnppFNEw3/wAAHFCTKvR1Uf+yGCq2KxZBvBQT1HlKZDmaqkANLSTGv8x5TBbG9/el\n",
       "XxVDsMIPALUZobH3BvPeMqfXDdYrSU7j/ikBjZcf0YzB+oynW2Pl1JeT7PLwysl2669b3a4sjHUa\n",
       "gSSRSSX3fvnxUAAAAGIBnrtqQ38AABxO1hGG8j1V2Ceo8AvdKYALZ0JJoeVI517vWPY6UHr+nJB8\n",
       "qQEo+tjc/PlAN2fEoxW+oHo4Z+nIAWXeQ9Fn3CC3gZdFRirpjTZ869efW09lvEEyZHqY3nzgAwAA\n",
       "BFJtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAALVAABAAABAAAAAAAAAAAAAAAAAQAAAAAA\n",
       "AAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC\n",
       "AAADfHRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAALVAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABsAAAASAAAAAAACRlZHRzAAAAHGVs\n",
       "c3QAAAAAAAAAAQAAC1QAAAgAAAEAAAAAAvRtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAAB0\n",
       "AFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAKfbWlu\n",
       "ZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAAB\n",
       "AAACX3N0YmwAAACzc3RzZAAAAAAAAAABAAAAo2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAB\n",
       "sAEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAx\n",
       "YXZjQwFkABX/4QAYZ2QAFazZQbCWhAAAAwAEAAADAFA8WLZYAQAGaOvjyyLAAAAAHHV1aWRraEDy\n",
       "XyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAAAdAAAEAAAAABRzdHNzAAAAAAAAAAEA\n",
       "AAABAAAAwGN0dHMAAAAAAAAAFgAAAAEAAAgAAAAAAQAAEAAAAAACAAAEAAAAAAMAAAgAAAAAAQAA\n",
       "FAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAACAAAIAAAAAAEAABAAAAAAAgAABAAAAAABAAAI\n",
       "AAAAAAEAABAAAAAAAgAABAAAAAABAAAIAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQA\n",
       "AAAAAQAACAAAAAABAAAQAAAAAAIAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAdAAAAAQAAAIhz\n",
       "dHN6AAAAAAAAAAAAAAAdAAAOLwAAAk0AAAEGAAAApwAAASkAAADkAAABAQAAAM8AAAB+AAAAhQAA\n",
       "AJsAAADTAAAAoQAAAL0AAAB9AAAAuQAAAKEAAACHAAAAqAAAAG0AAAB7AAAAiAAAALgAAACPAAAA\n",
       "TgAAAI4AAABeAAAAeAAAAGYAAAAUc3RjbwAAAAAAAAABAAAALAAAAGJ1ZHRhAAAAWm1ldGEAAAAA\n",
       "AAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRh\n",
       "AAAAAQAAAABMYXZmNTcuODMuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_anim = ut.create_system_animation(frames, n_episodes * episode_length)\n",
    "plt.close()\n",
    "\n",
    "HTML(test_anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
